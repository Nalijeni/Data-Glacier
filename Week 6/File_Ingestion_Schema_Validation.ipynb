{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Ingestion and Schema Validation\n",
    "\n",
    "## Tasks Performed\n",
    "\n",
    "1. Read the file using different method\n",
    "\n",
    "2. Perform basic validation of the taken data\n",
    "\n",
    "3. Create a YAML file, and generate summary of file\n",
    "\n",
    "## Dataset\n",
    "\n",
    "I found the dataset(2.21GB) on Kraggle's site. You can also find on here: [Combined_Flights_2021](https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022?resource=download&select=Combined_Flights_2021.csv).\n",
    "\n",
    "*When you download the dataset and want to run this notebook, change the file path to yours.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the File Using Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading the File with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas read time: 22.055590867996216 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df_pandas = pd.read_csv(\"Combined_Flights_2021.csv\")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Pandas read time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading the File with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask read time: 0.18443703651428223 seconds\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df_dask = dd.read_csv(\"Combined_Flights_2021.csv\")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Dask read time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading the File with Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 23:35:30,234\tINFO worker.py:1614 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray read time: 0.708920955657959 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.data\n",
    "import time\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_ray = ray.data.read_csv(\"Combined_Flights_2021.csv\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Ray read time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Dask has the fastest computational speed.\n",
    "\n",
    "## 2. Basic Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 61 entries, FlightDate to DivAirportLandings\n",
      "dtypes: bool(2), float64(19), int64(22), string(18)"
     ]
    }
   ],
   "source": [
    "df = df_dask.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6311871"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=df.columns.str.replace('[#,@,&]','')\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FlightDate', 'Airline', 'Origin', 'Dest', 'Cancelled', 'Diverted',\n",
       "       'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDelay', 'ArrTime',\n",
       "       'ArrDelayMinutes', 'AirTime', 'CRSElapsedTime', 'ActualElapsedTime',\n",
       "       'Distance', 'Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek',\n",
       "       'Marketing_Airline_Network', 'Operated_or_Branded_Code_Share_Partners',\n",
       "       'DOT_ID_Marketing_Airline', 'IATA_Code_Marketing_Airline',\n",
       "       'Flight_Number_Marketing_Airline', 'Operating_Airline',\n",
       "       'DOT_ID_Operating_Airline', 'IATA_Code_Operating_Airline',\n",
       "       'Tail_Number', 'Flight_Number_Operating_Airline', 'OriginAirportID',\n",
       "       'OriginAirportSeqID', 'OriginCityMarketID', 'OriginCityName',\n",
       "       'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac',\n",
       "       'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'DestCityName',\n",
       "       'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'DepDel15',\n",
       "       'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff',\n",
       "       'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrDelay', 'ArrDel15',\n",
       "       'ArrivalDelayGroups', 'ArrTimeBlk', 'DistanceGroup',\n",
       "       'DivAirportLandings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.columns\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    int64\n",
       "      ...\n",
       "Name: count, dtype: int64\n",
       "Dask Name: value-counts-agg, 10 graph layers"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing value\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FlightDate',\n",
       " 'Airline',\n",
       " 'Origin',\n",
       " 'Dest',\n",
       " 'Cancelled',\n",
       " 'Diverted',\n",
       " 'CRSDepTime',\n",
       " 'DepTime',\n",
       " 'DepDelayMinutes',\n",
       " 'DepDelay',\n",
       " 'ArrTime',\n",
       " 'ArrDelayMinutes',\n",
       " 'AirTime',\n",
       " 'CRSElapsedTime',\n",
       " 'ActualElapsedTime',\n",
       " 'Distance',\n",
       " 'Year',\n",
       " 'Quarter',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'Marketing_Airline_Network',\n",
       " 'Operated_or_Branded_Code_Share_Partners',\n",
       " 'DOT_ID_Marketing_Airline',\n",
       " 'IATA_Code_Marketing_Airline',\n",
       " 'Flight_Number_Marketing_Airline',\n",
       " 'Operating_Airline',\n",
       " 'DOT_ID_Operating_Airline',\n",
       " 'IATA_Code_Operating_Airline',\n",
       " 'Tail_Number',\n",
       " 'Flight_Number_Operating_Airline',\n",
       " 'OriginAirportID',\n",
       " 'OriginAirportSeqID',\n",
       " 'OriginCityMarketID',\n",
       " 'OriginCityName',\n",
       " 'OriginState',\n",
       " 'OriginStateFips',\n",
       " 'OriginStateName',\n",
       " 'OriginWac',\n",
       " 'DestAirportID',\n",
       " 'DestAirportSeqID',\n",
       " 'DestCityMarketID',\n",
       " 'DestCityName',\n",
       " 'DestState',\n",
       " 'DestStateFips',\n",
       " 'DestStateName',\n",
       " 'DestWac',\n",
       " 'DepDel15',\n",
       " 'DepartureDelayGroups',\n",
       " 'DepTimeBlk',\n",
       " 'TaxiOut',\n",
       " 'WheelsOff',\n",
       " 'WheelsOn',\n",
       " 'TaxiIn',\n",
       " 'CRSArrTime',\n",
       " 'ArrDelay',\n",
       " 'ArrDel15',\n",
       " 'ArrivalDelayGroups',\n",
       " 'ArrTimeBlk',\n",
       " 'DistanceGroup',\n",
       " 'DivAirportLandings']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get header name\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file 'columns.yaml' created.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "columns = [\n",
    "    'FlightDate', 'Airline', 'Origin', 'Dest', 'Cancelled', 'Diverted',\n",
    "    'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDelay', 'ArrTime',\n",
    "    'ArrDelayMinutes', 'AirTime', 'CRSElapsedTime', 'ActualElapsedTime',\n",
    "    'Distance', 'Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek',\n",
    "    'MarketingAirlineNetwork', 'OperatedorBrandedCodeSharePartners',\n",
    "    'DOTIDMarketingAirline', 'IATACodeMarketingAirline',\n",
    "    'FlightNumberMarketingAirline', 'OperatingAirline', 'DOTIDOperatingAirline',\n",
    "    'IATACodeOperatingAirline', 'TailNumber', 'FlightNumberOperatingAirline',\n",
    "    'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID',\n",
    "    'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName',\n",
    "    'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID',\n",
    "    'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac',\n",
    "    'DepDel15', 'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff',\n",
    "    'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrDelay', 'ArrDel15',\n",
    "    'ArrivalDelayGroups', 'ArrTimeBlk', 'DistanceGroup', 'DivAirportLandings'\n",
    "]\n",
    "\n",
    "# Data to be written to the YAML file\n",
    "data = {'columns': columns}\n",
    "\n",
    "# Write data to a YAML file\n",
    "with open('columns.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False)\n",
    "\n",
    "print(\"YAML file 'columns.yaml' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column validation failed. Kindly check the column names and order.\n",
      "File Summary: {'Total number of rows': 6311871, 'Total number of columns': 61, 'File size (bytes)': 112945}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# Step 1: Read the YAML configuration file\n",
    "with open(\"columns.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Step 2: Validate DataFrame structure against YAML\n",
    "if list(df.columns) == config[\"columns\"]:\n",
    "    print(\"Column validation passed\")\n",
    "else:\n",
    "    print(\"Column validation failed. Kindly check the column names and order.\")\n",
    "\n",
    "# Step 3: Write DataFrame to a gzipped, pipe separated text file\n",
    "df_subset = df.head(2000)  # selecting the first 2000 rows\n",
    "df_subset.to_csv(\"output.csv.gz\", sep=\"|\", compression=\"gzip\", index=False)\n",
    "\n",
    "# Step 4: Create and print a summary of the file\n",
    "summary = {\n",
    "    \"Total number of rows\": len(df),\n",
    "    \"Total number of columns\": len(df.columns),\n",
    "    \"File size (bytes)\": os.path.getsize(\"output.csv.gz\")\n",
    "}\n",
    "\n",
    "print(\"File Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
